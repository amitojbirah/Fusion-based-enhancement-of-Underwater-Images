{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHPvKBLqKwWU",
        "outputId": "469c11ea-4ffd-495c-b120-bac51dcc745f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn4_5J4UTYyf"
      },
      "outputs": [],
      "source": [
        "!unzip /content/gdrive/MyDrive/raw-890.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM8S9DjPXjTP"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import numpy as np\n",
        "import os #, shutil\n",
        "from tensorflow.keras.layers import *\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pickle\n",
        "\n",
        "\n",
        "import fusionmodule as fuseMod\n",
        "import contrastmodule as contMod\n",
        "import illuminancemodule as illumMod\n",
        "from PIL import Image, ImageStat\n",
        "\n",
        "tf.disable_v2_behavior()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i97MpbER7dxY"
      },
      "source": [
        "## **Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TVsGGZC7S5F"
      },
      "outputs": [],
      "source": [
        "n_epochs = 10\n",
        "batch_size = 8\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZWCh7ZEdcfy"
      },
      "source": [
        "## K-Estimation Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWwWct9FJIHR"
      },
      "outputs": [],
      "source": [
        "def Aod_net(X):\n",
        "\n",
        "  c1 = Conv2D(3,1,1,padding=\"SAME\",activation=\"relu\",kernel_initializer=tf.initializers.random_normal(stddev=0.02),\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(X)\n",
        "\n",
        "  c2 = Conv2D(3,3,1,padding=\"SAME\",activation=\"relu\",kernel_initializer=tf.initializers.random_normal(stddev=0.02),\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(c1)\n",
        "\n",
        "  c1c2 = tf.concat([c1,c2],axis=-1)\n",
        "\n",
        "  c3 = Conv2D(3,5,1,padding=\"SAME\",activation=\"relu\",kernel_initializer=tf.initializers.random_normal(stddev=0.02),\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(c1c2)\n",
        "\n",
        "  c2c3 = tf.concat([c2,c3],axis=-1)\n",
        "\n",
        "  c4 = Conv2D(3,7,1,padding=\"SAME\",activation=\"relu\",kernel_initializer=tf.initializers.random_normal(stddev=0.02),\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(c2c3)\n",
        "\n",
        "  c1c2c3c4 = tf.concat([c1,c2,c3,c4],axis=-1)\n",
        "\n",
        "  c5 = Conv2D(3,3,1,padding=\"SAME\",activation=\"relu\",kernel_initializer=tf.initializers.random_normal(stddev=0.02),\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(c1c2c3c4)\n",
        "\n",
        "  K = c5\n",
        "\n",
        "  output = ReLU(max_value=1.0)(tf.math.multiply(K,X) - K + 1.0)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLewmbK37I29"
      },
      "source": [
        "## **Data Loading & Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIcPe_UCcNn8"
      },
      "outputs": [],
      "source": [
        "def setup_data_paths(orig_images_path,hazy_images_path):\n",
        "\n",
        "  orig_image_paths = glob.glob(orig_images_path + \"/*.png\")\n",
        "  n = len(orig_image_paths)\n",
        "  random.shuffle(orig_image_paths)\n",
        "\n",
        "  train_keys = orig_image_paths[:int(0.90*n)]\n",
        "  val_keys = orig_image_paths[int(0.90*n):]\n",
        "\n",
        "\n",
        "  split_dict = {}\n",
        "  for key in train_keys:\n",
        "    split_dict[key] = 'train'\n",
        "  for key in val_keys:\n",
        "    split_dict[key] = 'val'\n",
        "\n",
        "  train_data = []\n",
        "  val_data = []\n",
        "\n",
        "  hazy_image_paths = glob.glob(hazy_images_path + \"/*.png\")\n",
        "  for path in hazy_image_paths:\n",
        "    label = path.split('/')[-1]\n",
        "    orig_path = orig_images_path + \"/\" + label\n",
        "    if(split_dict[orig_path] == 'train'):\n",
        "      train_data.append([path,orig_path])\n",
        "    else: val_data.append([path,orig_path])\n",
        "\n",
        "  return train_data, val_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKvs6a0jRXXO"
      },
      "outputs": [],
      "source": [
        "def load_image(X):\n",
        "  raw = tf.io.read_file(X)\n",
        "  x= tf.image.decode_jpeg(raw,channels=3)\n",
        "  X = tf.image.resize(x,(480,640))\n",
        "  X = X / 255.0\n",
        "  return X\n",
        "\n",
        "def showImage(x):\n",
        "  x = np.asarray(x*255,dtype=np.int32)\n",
        "  plt.figure()\n",
        "  plt.imshow(x)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPV56lybcfne"
      },
      "outputs": [],
      "source": [
        "def create_datasets(train_data,val_data,batch_size):\n",
        "\n",
        "  train_ds_hazy = tf.data.Dataset.from_tensor_slices([data[0] for data in train_data]).map(lambda x: load_image(x))\n",
        "  train_ds_orig = tf.data.Dataset.from_tensor_slices([data[1] for data in train_data]).map(lambda x: load_image(x))\n",
        "  train_ds = tf.data.Dataset.zip((train_ds_hazy,train_ds_orig)).shuffle(100).repeat().batch(batch_size)\n",
        "\n",
        "  val_ds_hazy = tf.data.Dataset.from_tensor_slices([data[0] for data in val_data]).map(lambda x: load_image(x))\n",
        "  val_ds_orig = tf.data.Dataset.from_tensor_slices([data[1] for data in val_data]).map(lambda x: load_image(x))\n",
        "  val_ds = tf.data.Dataset.zip((val_ds_hazy,val_ds_orig)).shuffle(100).repeat().batch(batch_size)\n",
        "\n",
        "  iterator = tf.data.Iterator.from_structure(tf.data.get_output_types(train_ds),tf.data.get_output_shapes(train_ds))\n",
        "\n",
        "  train_init_op = iterator.make_initializer(train_ds)\n",
        "  val_init_op = iterator.make_initializer(val_ds)\n",
        "\n",
        "  return train_init_op, val_init_op, iterator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKa2Fg2T7nS7"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMuKJ59NHVg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d744e83-83c0-47a6-8623-e5a48bea81ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py:370: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py:371: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py:373: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(9999)\n",
        "ops.reset_default_graph()\n",
        "train_data, val_data = setup_data_paths(orig_images_path=\"/content/reference-890\", hazy_images_path=\"/content/raw-890\");\n",
        "train_init_op, val_init_op, iterator = create_datasets(train_data,val_data,batch_size)\n",
        "next_element = iterator.get_next()\n",
        "\n",
        "X = tf.placeholder(shape=(None,480,640,3),dtype=tf.float32)\n",
        "Y = tf.placeholder(shape=(None,480,640,3),dtype=tf.float32)\n",
        "dehazed_X = Aod_net(X)\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(dehazed_X-Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trainable_variables = tf.trainable_variables()\n",
        "gradients_and_vars = optimizer.compute_gradients(loss,trainable_variables)\n",
        "clipped_gradients = [(tf.clip_by_norm(gradient,0.1),var) for gradient,var in gradients_and_vars]\n",
        "optimizer = optimizer.apply_gradients(gradients_and_vars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IobqAjYMgsC1"
      },
      "outputs": [],
      "source": [
        "saver = tf.train.Saver()\n",
        "load_path = None\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  with tf.Session() as sess:\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "      sess.run(train_init_op)\n",
        "      batches = len(train_data) // batch_size\n",
        "      epoch_loss = 0.0\n",
        "      for batch in range(batches):\n",
        "\n",
        "        batch_data = sess.run(next_element)\n",
        "        batch_loss, _ = sess.run([loss,optimizer],feed_dict={X:batch_data[0],Y:batch_data[1]})\n",
        "        epoch_loss += batch_loss / float(batches)\n",
        "        if batch % 1000 == 0:\n",
        "          print(\"Training loss at batch %d: %f\\n\"%(batch,batch_loss))\n",
        "\n",
        "      train_loss = epoch_loss\n",
        "\n",
        "      sess.run(val_init_op)\n",
        "      batches= len(val_data) // batch_size\n",
        "      epoch_loss = 0.0\n",
        "      for batch in range(batches):\n",
        "        batch_data = sess.run(next_element)\n",
        "        batch_loss = sess.run(loss,feed_dict={X:batch_data[0],\n",
        "                                             Y:batch_data[1]})\n",
        "        epoch_loss += batch_loss / float(batches)\n",
        "        if batch % 100 == 0:\n",
        "          print(\"Validation loss at batch %d: %f\\n\"%(batch,batch_loss))\n",
        "          for j in range(-2 + batch_size//2):\n",
        "            x = batch_data[0][j].reshape((1,)+batch_data[0][j].shape)\n",
        "            y = batch_data[1][j].reshape((1,)+batch_data[1][j].shape)\n",
        "            dehazed_x = sess.run(dehazed_X,feed_dict={X:x,Y:y})\n",
        "            print(\"Image Number: %d\\n\"%(j))\n",
        "            showImage(x[0])\n",
        "            showImage(y[0])\n",
        "            showImage(dehazed_x[0])\n",
        "      val_loss = epoch_loss\n",
        "\n",
        "      saver.save(sess,'/content/models/model_checkpoint_' + str(epoch) + '.h5')\n",
        "\n",
        "      print(\"Epoch %d\\nTraining loss: %f\\nValidation loss: %f\\n\\n\"%(epoch,train_loss,val_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lCLSaQ2KbhH"
      },
      "outputs": [],
      "source": [
        "next_element = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(val_init_op)\n",
        "\n",
        "  for i in range(10):\n",
        "    batch_data = sess.run(next_element)\n",
        "    for j in range(4):\n",
        "      x = batch_data[0][j].reshape((1,)+batch_data[0][j].shape)\n",
        "      #showImage(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlvRxPSH60vT"
      },
      "source": [
        "## **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrn7TNF_km2k"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "train_data, val_data = setup_data_paths(orig_images_path=\"/content/reference-890\",\n",
        "                                        hazy_images_path = \"/content/raw-890\");\n",
        "train_init_op, val_init_op, iterator = create_datasets(train_data,val_data,batch_size)\n",
        "next_element = iterator.get_next()\n",
        "\n",
        "X = tf.placeholder(shape=(None,480,640,3),dtype=tf.float32)\n",
        "Y = tf.placeholder(shape=(None,480,640,3),dtype=tf.float32)\n",
        "dehazed_X = Aod_net(X)\n",
        "\n",
        "loss = tf.reduce_mean(tf.square(dehazed_X-Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "trainable_variables = tf.trainable_variables()\n",
        "gradients_and_vars = optimizer.compute_gradients(loss,trainable_variables)\n",
        "clipped_gradients = [(tf.clip_by_norm(gradient,0.1),var) for gradient,var in gradients_and_vars]\n",
        "optimizer = optimizer.apply_gradients(gradients_and_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqrvfKhqwIrX"
      },
      "source": [
        "##Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nEwD3ZRsE4o"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle_out = open(\"img_model.pkl\", mode = \"wb\")\n",
        "pickle.dump('/content/models/model_checkpoint_9.h5.data-00000-of-00001', pickle_out)\n",
        "pickle_out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZuMVtQQsUjO"
      },
      "outputs": [],
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "\n",
        "test_input_folder = \"/content/challenging-60\"\n",
        "test_output_folder = \"/content/dehazed_test_images\"\n",
        "if not os.path.exists(test_output_folder):\n",
        "  os.mkdir(test_output_folder)\n",
        "\n",
        "file_types = ['jpeg','jpg','png']\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess,'/content/models/model_checkpoint_9.h5')\n",
        "  test_image_paths = []\n",
        "  for file_type in file_types:\n",
        "    test_image_paths.extend(glob.glob(test_input_folder+\"/*.\"+file_type))\n",
        "\n",
        "\n",
        "  for path in test_image_paths:\n",
        "    image_label = path.split(test_input_folder)[-1][1:]\n",
        "    image = Image.open(path)\n",
        "    image = image.resize((640, 480))\n",
        "    image = np.asarray(image) / 255.0\n",
        "    image = image.reshape((1,) + image.shape)\n",
        "    dehazed_image = sess.run(dehazed_X,feed_dict={X:image,Y:image})\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,10))\n",
        "    axes[0].imshow(image[0])\n",
        "    axes[1].imshow(dehazed_image[0])\n",
        "    fig.tight_layout()\n",
        "\n",
        "    dehazed_image = np.asarray(dehazed_image[0] * 255,dtype=np.uint8)\n",
        "    mpl.image.imsave(test_output_folder + \"/\" + 'dehazed_' + image_label, dehazed_image)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "YlvRxPSH60vT",
        "qqrvfKhqwIrX",
        "R8I6Kto_YiJ5",
        "R-Kyg0T-Ya5l",
        "25ijnf0rYKSA"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}